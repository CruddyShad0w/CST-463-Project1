{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KPfnWsVwmZtk"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KqpBXMnA1t4U"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "warnings.simplefilter(action='ignore', category=UndefinedMetricWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yPVljS2mmZt2"
   },
   "source": [
    "# Predicting Credit Default.\n",
    "#### Identifying risky credit patterns\n",
    "\n",
    "We'll be analysing credit card data, collected in Taiwan (link below). Trying to predict patterns that lead to defaulting on credit. Various Machine Learning methods will be applied to the dataset. We will also try to derive some features to help our predictions. The 'real world' applications of these methods will be considered throughout our report. Balancing performance with predictive power will be a consideration throughout the report. \n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uEnm1Mb6mZt7"
   },
   "source": [
    "### Definitions:\n",
    "**Default:** After you’ve failed to make a payment on your credit card for 180 days, your issuer assumes you’re probably never going to. At this point, the issuer can (and usually does) close your card, write off what you owe as bad debt and sell your account to a collections agency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 614,
     "status": "ok",
     "timestamp": 1539810817639,
     "user": {
      "displayName": "Kyle Hays",
      "photoUrl": "",
      "userId": "01076447387379991295"
     },
     "user_tz": 420
    },
    "id": "4BM_SrRSmZuA",
    "outputId": "10e855f0-8c98-411c-b1e2-c552e9961290"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"default_cc_train.csv\", sep=',')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 683
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1099,
     "status": "ok",
     "timestamp": 1539810819367,
     "user": {
      "displayName": "Kyle Hays",
      "photoUrl": "",
      "userId": "01076447387379991295"
     },
     "user_tz": 420
    },
    "id": "rgprmh7ymZuS",
    "outputId": "90378561-ac9c-4c8b-b437-42f71c942151"
   },
   "outputs": [],
   "source": [
    "corr = df.corr()\n",
    "mask = np.zeros_like(corr,dtype=np.bool)\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0, square=True,\n",
    "            linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "plt.title('Correlation of features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 550
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 432,
     "status": "ok",
     "timestamp": 1539810829003,
     "user": {
      "displayName": "Kyle Hays",
      "photoUrl": "",
      "userId": "01076447387379991295"
     },
     "user_tz": 420
    },
    "id": "VYQM5WzPmZui",
    "outputId": "bd4c18c4-7fb3-4bb4-c30d-1b2896e94478"
   },
   "outputs": [],
   "source": [
    "df.info()\n",
    "print(\"Shape: \",df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-f9OugqymZuv"
   },
   "source": [
    "Looks like its a full 25000 rows with no null values. Does not look like any data cleaning will be needed only scaling and preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 393
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 627,
     "status": "ok",
     "timestamp": 1539810833908,
     "user": {
      "displayName": "Kyle Hays",
      "photoUrl": "",
      "userId": "01076447387379991295"
     },
     "user_tz": 420
    },
    "id": "8Rn3dWSgmZuy",
    "outputId": "23d803a1-1dfe-45bb-d0fa-bcb44f46b116",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.countplot(df['default.payment.next.month'])\n",
    "plt.title('Histogram of payment defaults')\n",
    "plt.xticks((0,1),('Default','Good Standing'))\n",
    "plt.xlabel('Default payments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 446,
     "status": "ok",
     "timestamp": 1539810838824,
     "user": {
      "displayName": "Kyle Hays",
      "photoUrl": "",
      "userId": "01076447387379991295"
     },
     "user_tz": 420
    },
    "id": "uC2HLzl_mZu9",
    "outputId": "8a599377-f07b-4e56-ead2-b3088f5e72b6"
   },
   "outputs": [],
   "source": [
    "print( 'Percentage of default: '+ str(100*len(df[df['default.payment.next.month'] ==1]) / len(df) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8VpT8lR5mZvS"
   },
   "source": [
    "About one in every 3.5-4 people will end up defaulting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 378
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 528,
     "status": "ok",
     "timestamp": 1539810839669,
     "user": {
      "displayName": "Kyle Hays",
      "photoUrl": "",
      "userId": "01076447387379991295"
     },
     "user_tz": 420
    },
    "id": "jsuAEjCjmZva",
    "outputId": "085aabda-8ab0-4256-e308-2e11ce2cd469"
   },
   "outputs": [],
   "source": [
    "sns.distplot(df['AGE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IX8Zh5_ZmZvq"
   },
   "source": [
    "Interesting distribution here, large concentrations around 28, 35, 43, and 52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 535,
     "status": "ok",
     "timestamp": 1539810840987,
     "user": {
      "displayName": "Kyle Hays",
      "photoUrl": "",
      "userId": "01076447387379991295"
     },
     "user_tz": 420
    },
    "id": "ngzIoUDumZvv",
    "outputId": "3b8e67e3-0df0-4891-c7dc-d6cabfc91fcd"
   },
   "outputs": [],
   "source": [
    "sns.countplot('EDUCATION',hue='default.payment.next.month',data=df)\n",
    "plt.title('Educational Distribution')\n",
    "plt.xlabel('Maximum Level of Education')\n",
    "L = plt.legend(title='Default')\n",
    "L.get_texts()[0].set_text('No')\n",
    "L.get_texts()[1].set_text('Yes')\n",
    "plt.xticks((0,1,2,3,4,5,6),('<12 grade','graduate school','university','high school','other','trade school','Not disclosed'),rotation=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ntx_bkVsmZv5"
   },
   "source": [
    "Our debtors are mostly educated people. There appears to be no significance in the relationship between education and defaulting on your credit card. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 431
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 519,
     "status": "ok",
     "timestamp": 1539810845007,
     "user": {
      "displayName": "Kyle Hays",
      "photoUrl": "",
      "userId": "01076447387379991295"
     },
     "user_tz": 420
    },
    "id": "wQ9isD9vmZv7",
    "outputId": "dc12c172-c25c-4c65-c1cc-b4d03afdd098"
   },
   "outputs": [],
   "source": [
    "#mar_map = {0:'Not Provided',1:'Married',2:'Single',3:'Unknown'}\n",
    "#mar_status = [mar_map[stat] for stat in df['MARRIAGE']]\n",
    "sns.countplot('MARRIAGE', hue='default.payment.next.month',data=df)\n",
    "plt.xticks((0,1,2,3),('Not Provided','Married','Single','Unknown'),rotation=45)\n",
    "L = plt.legend(title='Default')\n",
    "L.get_texts()[0].set_text('No')\n",
    "L.get_texts()[1].set_text('Yes')\n",
    "plt.title('Relationship Status')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wpAb4gfgmZwN"
   },
   "source": [
    "A greater percentage of married people end up defaulting on their debt. One would suspect otherwise, with the additional responsibility and future planning that usually comes with marriage. But perhaps single people have fewer financial burdens, like children, and are less likely to overextend themselves financially. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1608,
     "status": "ok",
     "timestamp": 1539810846825,
     "user": {
      "displayName": "Kyle Hays",
      "photoUrl": "",
      "userId": "01076447387379991295"
     },
     "user_tz": 420
    },
    "id": "iYGaCIJQmZwR",
    "outputId": "e1557018-cc94-4c47-f3d8-abfaf1f82f07"
   },
   "outputs": [],
   "source": [
    "plot = sns.countplot(df['LIMIT_BAL'],hue = df['default.payment.next.month'])\n",
    "plot.set_xticks(plot.get_xticks()[::5])\n",
    "plot = plt.xticks(rotation=90)\n",
    "plt.title('Histogram of Credit Limit Balances')\n",
    "L = plt.legend(title='Default')\n",
    "L.get_texts()[0].set_text('No')\n",
    "L.get_texts()[1].set_text('Yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fc6f2p7NmZwZ"
   },
   "source": [
    "Kind of a hard figure to see but shows the reationship between a persons balance limit and thier defualt. Generally a higher percentage of people with lower limit balances will end up defaulting. If you're a 'high risk' applicant the bank usually will only approve you for a smaller line of credit. This graph might help show why that is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 379
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 824,
     "status": "ok",
     "timestamp": 1539810847674,
     "user": {
      "displayName": "Kyle Hays",
      "photoUrl": "",
      "userId": "01076447387379991295"
     },
     "user_tz": 420
    },
    "id": "V3FVGS92mZwe",
    "outputId": "0f54daf1-ded1-4fcc-c8cd-9f1868252c31"
   },
   "outputs": [],
   "source": [
    "default_labs = {0:'Good Standing',1:'Default'}\n",
    "default = [default_labs[x] for x in df['default.payment.next.month']]\n",
    "sns.violinplot(x=default, y='LIMIT_BAL',data=df)\n",
    "plt.title(\"Limit Balance and default distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qEygpdQImZwp"
   },
   "source": [
    "Perhaps not very surprisingly, people with higher limit balances are less likely to to be defaulting. The defaulters had a lower average credit limit. Likely they already had a lower credit score to begin with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 379
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1044,
     "status": "ok",
     "timestamp": 1539810848857,
     "user": {
      "displayName": "Kyle Hays",
      "photoUrl": "",
      "userId": "01076447387379991295"
     },
     "user_tz": 420
    },
    "id": "mfpgQqUzmZws",
    "outputId": "fee83aba-f293-4393-b058-1d4616f6f477"
   },
   "outputs": [],
   "source": [
    "sns.violinplot('default.payment.next.month', y='AGE',data=df)\n",
    "plt.title('Default behavior by age distribution')\n",
    "plt.xticks((0,1),('Default','Good Standing'))\n",
    "plt.xlabel('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l7-55YVkmZxQ"
   },
   "source": [
    "Almost no difference at all in age distributions between defaulters and not. A little surprising actually. One would imagine younger people defaulting more. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b1aXPoNSmZxX"
   },
   "source": [
    "#### Bill amounts\n",
    "According to the correlation plot above, the most significant features for predicting default payments will be the BILL_AMT fields. Let's visualize a couple to see what we can infer from them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 393
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 515,
     "status": "ok",
     "timestamp": 1539810850316,
     "user": {
      "displayName": "Kyle Hays",
      "photoUrl": "",
      "userId": "01076447387379991295"
     },
     "user_tz": 420
    },
    "id": "o5UFmPu3mZxb",
    "outputId": "d7a94dc2-eb5f-488f-c104-7129bd5c2b59"
   },
   "outputs": [],
   "source": [
    "sns.distplot(df['BILL_AMT1'])\n",
    "plt.title('Distribution of Bill Amounts in month 1')\n",
    "plt.xlabel('Money Owed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZTUqPjuDmZxs"
   },
   "source": [
    "A very steep distirbution toward the lowerd end of money owed. Is this the general pattern this data will follow? Lets look at another month to be sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 393
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 573,
     "status": "ok",
     "timestamp": 1539810851624,
     "user": {
      "displayName": "Kyle Hays",
      "photoUrl": "",
      "userId": "01076447387379991295"
     },
     "user_tz": 420
    },
    "id": "QKMkOJGsmZxu",
    "outputId": "c38f5577-b990-4812-d42b-4cccb475124c"
   },
   "outputs": [],
   "source": [
    "sns.distplot(df['BILL_AMT6'])\n",
    "plt.title('Distribution of Bill Amounts in month 6')\n",
    "plt.xlabel('Money Owed')\n",
    "plt.xlim((-50000,600000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W5xS9h9kmZyA"
   },
   "source": [
    "Almost exactly the same. This seems to make sense. Most people won't want ot have too much debt. The vast majority of people have debt below about 50,000 (not sure if this is measured in Dollars or Yen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 393
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 479,
     "status": "ok",
     "timestamp": 1539810853286,
     "user": {
      "displayName": "Kyle Hays",
      "photoUrl": "",
      "userId": "01076447387379991295"
     },
     "user_tz": 420
    },
    "id": "3d8_GLbEmZyH",
    "outputId": "a4042f9e-b5ae-4bf5-935d-81e29e765471"
   },
   "outputs": [],
   "source": [
    "sns.countplot(x='PAY_2', hue = 'default.payment.next.month' , data = df)\n",
    "plt.title('Defaults by payment status')\n",
    "plt.xlabel('Payment Status')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4CQHm_SXmZyb"
   },
   "source": [
    "Not everyone that pays on time, or is paid up in a given month is guaranteed not to default. But for the folks that are already a few months late, it looks like you're more likely to end up in default than you are to end up paying off your debt. As we saw earlier in the correlation plot, payment status will be a very strong predictor of default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SSTHDhk9mZyd"
   },
   "source": [
    "### Derived Features: \n",
    "#### To add or not to add?\n",
    "Our team played with a few strategies to sythesize some more features. Some features tested were: ratio of money owed to total balance, sum off amounts owed across each month, as well as a couple others trying to get something more meaningful out of the 'limit balance', 'pay amount' and 'bill amount'. Below is some featur engineering we've done, and through this we've managed to bump our average predictions up a couple %. No revolutionary gains, but something is better than nothing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2IAEg6_K2gus"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Transformer class for the\n",
    "    [default of credit card clients]\n",
    "    (https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients)\n",
    "Data Set.\n",
    "\n",
    "Usage:\n",
    "    import preprocessing\n",
    "    transformer = preprocessing.Transformer()\n",
    "    X_train = transformer.fit_transform(df_train)\n",
    "    X_test = transformer.transform(df_test)\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "\n",
    "def _get_cols(prefix, from_idx, to_idx):\n",
    "    res = []\n",
    "    for i in range(from_idx, to_idx + 1):\n",
    "        res.append(prefix + str(i))\n",
    "    return res\n",
    "\n",
    "\n",
    "class FeatureEngineer(TransformerMixin):\n",
    "    \"\"\"\n",
    "    A Transformer for Feature Enginnering\n",
    "    \"\"\"\n",
    "    PAY_AMTS = _get_cols('PAY_AMT', 1, 6)\n",
    "    BILL_AMTS = _get_cols('BILL_AMT', 1, 6)\n",
    "    PAYS = ['PAY_0'] + _get_cols('PAY_', 2, 6)\n",
    "\n",
    "    def fit(self, dataframe):\n",
    "        \"\"\"\n",
    "        :type dataframe pandas.DataFrame\n",
    "        \"\"\"\n",
    "        return self\n",
    "\n",
    "    def transform(self, dataframe):\n",
    "        \"\"\"\n",
    "        :type dataframe pandas.DataFrame\n",
    "        \"\"\"\n",
    "        dataframe['TOT_PAY_AMT'] = self._tot_pay_amt(dataframe)\n",
    "        dataframe['TOT_BILL_AMT'] = self._tot_bill_amt(dataframe)\n",
    "        dataframe['TOT_MOD'] = self._tot_month_of_delays(dataframe)\n",
    "        dataframe['NUM_NO_COMSP'] = self._num_of_no_consumption(dataframe)\n",
    "        dataframe['NUM_NO_DLY'] = self._num_of_no_delay(dataframe)\n",
    "        return dataframe\n",
    "\n",
    "    def _tot_pay_amt(self, dataframe):\n",
    "        return dataframe[self.PAY_AMTS].sum(axis=1)\n",
    "\n",
    "    def _tot_bill_amt(self, dataframe):\n",
    "        return dataframe[self.BILL_AMTS].sum(axis=1)\n",
    "\n",
    "    def _tot_month_of_delays(self, dataframe):\n",
    "        return dataframe[self.PAYS].replace([-2, -1], 0).sum(axis=1)\n",
    "\n",
    "    def _num_of_no_consumption(self, dataframe):\n",
    "        return (dataframe[self.PAYS] == -2).sum(axis=1)\n",
    "\n",
    "    def _num_of_no_delay(self, dataframe):\n",
    "        return (dataframe[self.PAYS] == -1).sum(axis=1)\n",
    "\n",
    "\n",
    "class NumFeatureSelector(TransformerMixin):\n",
    "    \"\"\"\n",
    "    Select Numeric Features\n",
    "    \"\"\"\n",
    "    FEATURES_ = [\n",
    "        'LIMIT_BAL', 'AGE', 'TOT_PAY_AMT', 'TOT_BILL_AMT', 'TOT_MOD',\n",
    "        'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5',\n",
    "        'BILL_AMT6', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4',\n",
    "        'PAY_AMT5', 'PAY_AMT6'\n",
    "    ]\n",
    "\n",
    "    def __init__(self, features):\n",
    "        super().__init__()\n",
    "        self.features = features\n",
    "\n",
    "    def fit(self, dataframe):\n",
    "        \"\"\"\n",
    "        :type dataframe pandas.DataFrame\n",
    "        \"\"\"\n",
    "        return self\n",
    "\n",
    "    def transform(self, dataframe):\n",
    "        \"\"\"\n",
    "        :type dataframe pandas.DataFrame\n",
    "        \"\"\"\n",
    "        return dataframe[self.features].values\n",
    "\n",
    "\n",
    "class CatFeatureSelector(TransformerMixin):\n",
    "    \"\"\"\n",
    "    Select Categorical Features\n",
    "    \"\"\"\n",
    "    FEATURES_ = [\n",
    "        'SEX', 'EDUCATION', 'MARRIAGE', 'PAY_0',\n",
    "        'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6',\n",
    "        'NUM_NO_COMSP', 'NUM_NO_DLY'\n",
    "    ]\n",
    "\n",
    "    def __init__(self, features=None):\n",
    "        super().__init__()\n",
    "        self._encoder = None\n",
    "        if features is None:\n",
    "            features = self.CAT_FEATURES_\n",
    "        self.features = features\n",
    "\n",
    "    def fit(self, dataframe):\n",
    "        \"\"\"\n",
    "        :type dataframe pandas.DataFrame\n",
    "        \"\"\"\n",
    "        self._encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "        X = dataframe[self.features].astype('int32')\n",
    "        X -= X.min().min()\n",
    "        self._encoder.fit(X)\n",
    "        return self\n",
    "\n",
    "    def transform(self, dataframe):\n",
    "        \"\"\"\n",
    "        :type dataframe pandas.DataFrame\n",
    "        \"\"\"\n",
    "        X = dataframe[self.features].astype('int32')\n",
    "        X -= X.min().min()\n",
    "        return self._encoder.transform(X).toarray()\n",
    "\n",
    "    def feature_indices(self):\n",
    "        return self._encoder.feature_indices_\n",
    "\n",
    "\n",
    "class Transformer(TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transform the `default of credit card clients` data\n",
    "    \"\"\"\n",
    "    _feature_enginner = FeatureEngineer()\n",
    "\n",
    "    def __init__(self, num_features=None, cat_features=None):\n",
    "        super().__init__()\n",
    "        self._need_to_fit = True\n",
    "        self._pipe = None\n",
    "        self.df = None\n",
    "        self.cat_selector = None\n",
    "        if num_features is None:\n",
    "            num_features = NumFeatureSelector.FEATURES_\n",
    "        if cat_features is None:\n",
    "            cat_features = CatFeatureSelector.FEATURES_\n",
    "        self.num_features = num_features\n",
    "        self.cat_features = cat_features\n",
    "\n",
    "    def fit(self, dataframe):\n",
    "        \"\"\"\n",
    "        :type dataframe pandas.DataFrame\n",
    "        \"\"\"\n",
    "        self._need_to_fit = True\n",
    "        return self\n",
    "\n",
    "    def transform(self, dataframe):\n",
    "        \"\"\"\n",
    "        :type dataframe pandas.DataFrame\n",
    "        \"\"\"\n",
    "        self.df = self._feature_enginner.fit_transform(dataframe)\n",
    "        if self._need_to_fit:\n",
    "            self._need_to_fit = False\n",
    "            self.cat_selector = CatFeatureSelector(self.cat_features)\n",
    "            self._pipe = Pipeline([\n",
    "                ('Feature Union', FeatureUnion([\n",
    "                    ('Numeric Features', NumFeatureSelector(self.num_features)),\n",
    "                    ('Encoded Categorical Features', self.cat_selector),\n",
    "                ])),\n",
    "                ('Standard Scaler', StandardScaler()),\n",
    "            ])\n",
    "            return self._pipe.fit_transform(self.df)\n",
    "        return self._pipe.transform(self.df)\n",
    "\n",
    "    def feature_importances(self, importances):\n",
    "        \"\"\"\n",
    "        :type importances numpy.ndarray\n",
    "        \"\"\"\n",
    "        indices = self.cat_selector.feature_indices()\n",
    "        col = len(self.num_features)\n",
    "        cat_scores = np.zeros(len(self.cat_features))\n",
    "        for i in range(1, len(indices)):\n",
    "            cat_scores[i - 1] = np.sum(importances[\n",
    "                (col + indices[i - 1]):(col + indices[i])\n",
    "            ])\n",
    "        return pd.DataFrame({\n",
    "            'feature': self.num_features + self.cat_features,\n",
    "            'importance': np.concatenate((\n",
    "                importances[:len(self.num_features)],\n",
    "                cat_scores\n",
    "            ))\n",
    "        }).sort_values(by=['importance'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n2jRdkqiU9Fs"
   },
   "source": [
    "The `Transformer` class wraps the entire preprocessing logic. It contains feature engineering, selecting numeric and categorical features and transform them into indicator variables. It also provides a utility method to restore the original feature importance for the categorical features.\n",
    "\n",
    "The new features are \n",
    "\n",
    "`TOT_PAY_AMT`: Total payment in the 6 months.\n",
    "\n",
    "`TOT_BILL_AMT`: Total payment in the 6 months.\n",
    "\n",
    "`TOT_MOD`: Number of the month of delay. \n",
    "\n",
    "`NUM_NO_COMSP`: Number of months without consumption (with pay value of `-2`)\n",
    "\n",
    "`NUM_NO_DLY`: Number of months paid on time in full (with pay value of `-1`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rMKOWoBD4mtS"
   },
   "outputs": [],
   "source": [
    "transformer = Transformer()\n",
    "X = transformer.fit_transform(df)\n",
    "df = transformer.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 544,
     "status": "ok",
     "timestamp": 1539810959862,
     "user": {
      "displayName": "Kyle Hays",
      "photoUrl": "",
      "userId": "01076447387379991295"
     },
     "user_tz": 420
    },
    "id": "Em-OeURx4pXr",
    "outputId": "37bd7e45-eadd-46f5-92ad-320237aa8f5a"
   },
   "outputs": [],
   "source": [
    "def get_color(x):\n",
    "    return 'b' if x == 0 else 'r'\n",
    "\n",
    "df[df['TOT_BILL_AMT'] <= 0]['default.payment.next.month'].plot(kind='hist', density=1, alpha=.3)\n",
    "df[df['TOT_BILL_AMT'] > 0]['default.payment.next.month'].plot(kind='hist', density=1, alpha=.3)\n",
    "plt.legend(['Total Bill Amount <= 0', 'Total Bill Amount > 0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZQV3wvLcVGyl"
   },
   "source": [
    "We found people with negative total bill amount are more likely to default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rzSO31Fh_DHv"
   },
   "outputs": [],
   "source": [
    "plt.scatter(df['TOT_PAY_AMT'], df['TOT_BILL_AMT'], s=2, alpha=0.5, c=list(map(get_color, df['default.payment.next.month'])))\n",
    "plt.xlabel('Total Payment')\n",
    "plt.ylabel('Total Bill')\n",
    "plt.xticks(rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SDyxkKjL_EWF"
   },
   "outputs": [],
   "source": [
    "plt.scatter(df['TOT_MOD'], df['TOT_BILL_AMT'], s=2, alpha=0.5, c=list(map(get_color, df['default.payment.next.month'])))\n",
    "plt.xlabel('Total Month of Delays')\n",
    "plt.ylabel('Total Bill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M0kDovFNVNia"
   },
   "source": [
    "The total month of delays is the sum of the `PAY` columns excluding the negative values. This new feature indicates people with high total month of delays are more likely to default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vMADFxVxmZyf"
   },
   "source": [
    "# Trying classifiers\n",
    "We will test out a broad suite of Machine Learning algorithms, as well as a few ensemble methods to find the best means of predicting defaulters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PLIC7h74mZyh"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.neighbors import KNeighborsClassifier as knn\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import  VotingClassifier,GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, SGDRegressor,LinearRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UlNA5WMymZyl"
   },
   "outputs": [],
   "source": [
    "pd.set_option('mode.chained_assignment', None)\n",
    "X = transformer.fit_transform(df)\n",
    "y = df['default.payment.next.month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 454
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5009,
     "status": "ok",
     "timestamp": 1539810979872,
     "user": {
      "displayName": "Kyle Hays",
      "photoUrl": "",
      "userId": "01076447387379991295"
     },
     "user_tz": 420
    },
    "id": "XMBLihJv3EOl",
    "outputId": "0694d64b-474c-4a1c-f2e5-05621ac6b589"
   },
   "outputs": [],
   "source": [
    "rand_frst = RandomForestClassifier(n_estimators=100).fit(X, y)\n",
    "transformer.feature_importances(rand_frst.feature_importances_).plot(kind='bar', x='feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sJup6Ozx3FuE"
   },
   "outputs": [],
   "source": [
    "transformer = Transformer(cat_features=[\n",
    "    'SEX', 'MARRIAGE', 'PAY_0'\n",
    "])\n",
    "X = transformer.fit_transform(df)\n",
    "y = df['default.payment.next.month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5248,
     "status": "ok",
     "timestamp": 1539811000942,
     "user": {
      "displayName": "Kyle Hays",
      "photoUrl": "",
      "userId": "01076447387379991295"
     },
     "user_tz": 420
    },
    "id": "obbzGlLB3LkE",
    "outputId": "ca7a5214-049c-442d-9566-e597e790ca16"
   },
   "outputs": [],
   "source": [
    "rand_frst = RandomForestClassifier(n_estimators=100).fit(X, y)\n",
    "transformer.feature_importances(rand_frst.feature_importances_).plot(kind='bar', x='feature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RjNo-oT5VS1g"
   },
   "source": [
    "One of the derived feature `TOT_MOD` has high feature importance value according to a random forest classifier.\n",
    "We remove the categorical variables with low feature importance value to reduce the dimensionality and improve the performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3BuOPDwLmZzB"
   },
   "source": [
    "### ML Specific Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dZ5NTELU3YeM"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import \\\n",
    "        GridSearchCV, \\\n",
    "        learning_curve, \\\n",
    "        train_test_split\n",
    "from sklearn.metrics import \\\n",
    "        accuracy_score, \\\n",
    "        confusion_matrix, \\\n",
    "        precision_recall_fscore_support\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, name, base_estimator, param_grid):\n",
    "        self.name = name\n",
    "        self.base_estimator = base_estimator\n",
    "        self.param_grid = param_grid\n",
    "        self.id = None\n",
    "        self.best_estimator = None\n",
    "        self.best_params = None\n",
    "        self.train_score = None\n",
    "        self.accuracy = None\n",
    "        self.precision = None\n",
    "        self.recall = None\n",
    "        self.fbeta = None\n",
    "        self.support = None\n",
    "        self.tn = None\n",
    "        self.tp = None\n",
    "        self.fn = None\n",
    "        self.fp = None\n",
    "\n",
    "    def as_df(self):\n",
    "        return pd.DataFrame({\n",
    "            'id': [self.id],\n",
    "            'name': [self.name],\n",
    "            'best_params': [self.best_params],\n",
    "            'train_score': [self.train_score],\n",
    "            'accuracy': [self.accuracy],\n",
    "            'precision': [self.precision],\n",
    "            'recal': [self.recall],\n",
    "            'fbeta_score': [self.fbeta],\n",
    "            'support': [self.support],\n",
    "            'tn': [self.tn],\n",
    "            'tp': [self.tp],\n",
    "            'fn': [self.fn],\n",
    "            'fp': [self.fp]\n",
    "        })\n",
    "\n",
    "\n",
    "class ModelSelection:\n",
    "    TARGET_ = 'default.payment.next.month'\n",
    "\n",
    "    def __init__(self, df, transformer, test_size, max_parallelism=None):\n",
    "        df_train, df_test = train_test_split(df, test_size=test_size)\n",
    "        self.X_train = transformer.fit_transform(df_train)\n",
    "        self.y_train = df_train[self.TARGET_]\n",
    "        self.X_test = transformer.transform(df_test)\n",
    "        self.y_test = df_test[self.TARGET_]\n",
    "        self.models = []\n",
    "        self.max_parallelism = max_parallelism\n",
    "\n",
    "    def search_and_test(self, name, base_estimator, param_grid, cv=5):\n",
    "        \"\"\"\n",
    "        Perform Grid Search on the param grid & Test the best model\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        name: string\n",
    "\n",
    "        base_estimator: sklearn.estimator\n",
    "\n",
    "        param_grid: dict\n",
    "            param_grid for GridSearch\n",
    "\n",
    "        cv: int, cross-validation generator or an iterable, optional\n",
    "        \"\"\"\n",
    "        model = Model(name, base_estimator, param_grid)\n",
    "        gs = GridSearchCV(base_estimator, param_grid=param_grid,\n",
    "                          cv=cv, n_jobs=self.max_parallelism)\n",
    "        gs.fit(self.X_train, self.y_train)\n",
    "        model.best_params = gs.best_params_\n",
    "        model.best_estimator = gs.best_estimator_\n",
    "        model.train_score = gs.best_score_\n",
    "        model.best_estimator.fit(self.X_train, self.y_train)\n",
    "        y_pred = model.best_estimator.predict(self.X_test)\n",
    "        model.accuracy = accuracy_score(self.y_test, y_pred)\n",
    "        cm = confusion_matrix(self.y_test, y_pred)\n",
    "        model.tn, model.fp, model.fn, model.tp = cm.ravel()\n",
    "        scores = precision_recall_fscore_support(\n",
    "            self.y_test, y_pred, average='binary'\n",
    "        )\n",
    "        model.precision, model.recall, model.fbeta, model.support = scores\n",
    "        model.id = len(self.models)\n",
    "        self.models.append(model)\n",
    "        return model\n",
    "\n",
    "    def plot_confusion_matrix(self, model, normalize=True):\n",
    "        \"\"\"\n",
    "        Plots the confusion matrix for the model\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        model : Model\n",
    "            A model should be contructed by `search_and_test` method\n",
    "        \"\"\"\n",
    "        df_cm = pd.DataFrame({\n",
    "            0: [model.tn, model.fn],\n",
    "            1: [model.fp, model.tp]\n",
    "        })\n",
    "        if normalize:\n",
    "            total = model.tn + model.tp + model.fn + model.fp\n",
    "            df_cm = df_cm.astype('float') / total\n",
    "        plt.figure()\n",
    "        sns.heatmap(df_cm, annot=True)\n",
    "        plt.title('Confusion Matrix\\n{}\\n{}'.format(\n",
    "            model.name, model.best_params\n",
    "        ))\n",
    "        plt.ylabel(\"True\")\n",
    "        plt.xlabel(\"Prediction\")\n",
    "        plt.tight_layout()\n",
    "        return plt\n",
    "\n",
    "    def plot_learning_curve(self, model, ylim=None, cv=None,\n",
    "                            train_sizes=np.linspace(.5, 1.0, 5)):\n",
    "        \"\"\"\n",
    "        Generate a simple plot of the test and training learning curve.\n",
    "        http://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        model : Model\n",
    "            A model should be contructed by `search_and_test` method\n",
    "\n",
    "        ylim : tuple, shape (ymin, ymax), optional\n",
    "            Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "        cv : int, cross-validation generator or an iterable, optional\n",
    "\n",
    "        train_sizes : array-like, shape (n_ticks,), dtype float or int\n",
    "            Relative or absolute numbers of training examples that will be used to\n",
    "            generate the learning curve. If the dtype is float, it is regarded as a\n",
    "            fraction of the maximum size of the training set (that is determined\n",
    "            by the selected validation method), i.e. it has to be within (0, 1].\n",
    "            Otherwise it is interpreted as absolute sizes of the training sets.\n",
    "        \"\"\"\n",
    "        plt.figure()\n",
    "        plt.title(\"{}\\n{}\".format(model.name, model.best_params))\n",
    "        if ylim is not None:\n",
    "            plt.ylim(*ylim)\n",
    "        plt.xlabel(\"Training examples\")\n",
    "        plt.ylabel(\"Score\")\n",
    "        train_sizes, train_scores, test_scores = learning_curve(\n",
    "            model.best_estimator, self.X_train, self.y_train, cv=cv,\n",
    "            n_jobs=self.max_parallelism, train_sizes=train_sizes)\n",
    "        train_scores_mean = np.mean(train_scores, axis=1)\n",
    "        train_scores_std = np.std(train_scores, axis=1)\n",
    "        test_scores_mean = np.mean(test_scores, axis=1)\n",
    "        test_scores_std = np.std(test_scores, axis=1)\n",
    "        plt.grid()\n",
    "\n",
    "        plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                         train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                         color=\"r\")\n",
    "        plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                         test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "        plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "                 label=\"Training score\")\n",
    "        plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "                 label=\"Cross-validation score\")\n",
    "\n",
    "        plt.legend(loc=\"best\")\n",
    "        return plt\n",
    "\n",
    "    def get_predictions(self, model):\n",
    "        \"\"\"\n",
    "        Get the predictions from a model using different params\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        model : Model\n",
    "            A model should be contructed by `search_and_test` method\n",
    "        \"\"\"\n",
    "        flat = [[(k, v) for v in vs] for k, vs in model.param_grid.items()]\n",
    "        params_list = [dict(items) for items in product(*flat)]\n",
    "        predictions = []\n",
    "        clf = model.base_estimator\n",
    "        for params in params_list:\n",
    "            clf.set_params(**params)\n",
    "            clf.fit(self.X_train, self.y_train)\n",
    "            y_pred = clf.predict(self.X_test)\n",
    "            predictions.append(y_pred)\n",
    "        return predictions\n",
    "\n",
    "    def plot_precision_recall(self, model):\n",
    "        \"\"\"\n",
    "        Create the Precision-Recall plot for the model\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        model : Model\n",
    "            A model should be contructed by `search_and_test` method\n",
    "        \"\"\"\n",
    "        plt.figure()\n",
    "        predictions = self.get_predictions(model)\n",
    "        for y_pred in predictions:\n",
    "            precision, recall, f, beta = precision_recall_fscore_support(\n",
    "                self.y_test, y_pred, average='binary'\n",
    "            )\n",
    "            plt.scatter(precision, recall)\n",
    "        plt.title(model.name)\n",
    "        plt.xlabel('Precision')\n",
    "        plt.ylabel('Recall')\n",
    "        return plt\n",
    "\n",
    "    def plot(self, model):\n",
    "        \"\"\"\n",
    "        Generates all the plots we have for the model\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        model : Model\n",
    "            A model should be contructed by `search_and_test` method\n",
    "        \"\"\"\n",
    "        self.plot_confusion_matrix(model)\n",
    "        self.plot_precision_recall(model)\n",
    "        self.plot_learning_curve(model)\n",
    "\n",
    "    def as_df(self):\n",
    "        \"\"\"\n",
    "        Output the models as a pandas dataframe\n",
    "        \"\"\"\n",
    "        return pd.concat(\n",
    "            [model.as_df() for model in self.models]\n",
    "        ).set_index('id').sort_values(by=['accuracy'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = ModelSelection(df, transformer, test_size=0.3, max_parallelism=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VdNaMJZdmZzY"
   },
   "source": [
    "## Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1837753,
     "status": "ok",
     "timestamp": 1539815365417,
     "user": {
      "displayName": "Kyle Hays",
      "photoUrl": "",
      "userId": "01076447387379991295"
     },
     "user_tz": 420
    },
    "id": "XeL5kNVamZzc",
    "outputId": "7e5f17fa-d03b-432b-b80c-bec776176e41"
   },
   "outputs": [],
   "source": [
    "gb = selector.search_and_test(\n",
    "    'Gradient Boosting Classifier',\n",
    "    GradientBoostingClassifier(),\n",
    "    {\n",
    "        'n_estimators': range(1, 20, 2),\n",
    "        'max_depth': range(1, 10, 2),\n",
    "        'learning_rate': [0.01, 0.1, 1]\n",
    "    }\n",
    ")\n",
    "selector.plot(gb)\n",
    "gb.as_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "38aTFc0vmZz7"
   },
   "source": [
    "## Stochastic Gradient Desecent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 189
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1235092,
     "status": "ok",
     "timestamp": 1539816602437,
     "user": {
      "displayName": "Kyle Hays",
      "photoUrl": "",
      "userId": "01076447387379991295"
     },
     "user_tz": 420
    },
    "id": "zRm3dyV1mZz8",
    "outputId": "50323b3f-7597-4394-c0d0-54a9fedbce90"
   },
   "outputs": [],
   "source": [
    "sgd = selector.search_and_test(\n",
    "    'Stochastic Gradient Desecent Classifier',\n",
    "    SGDClassifier(),\n",
    "    {\n",
    "        'alpha': [0.001, 0.01, 0.1, 1],\n",
    "        'loss': ['hinge', 'modified_huber', 'log'],\n",
    "        'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "        'class_weight': [\n",
    "            {0: 1, 1: 0.75},\n",
    "            {0: 1, 1: 1},\n",
    "            {0: 1, 1: 1.25},\n",
    "            {0: 1, 1: 1.5},\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "selector.plot(sgd)\n",
    "sgd.as_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sXfkNDaVmZ0Y"
   },
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MR3KFMeomZ0Z"
   },
   "outputs": [],
   "source": [
    "svc = selector.search_and_test(\n",
    "    'Support Vector Machine Classifier',\n",
    "    svm.SVC(),\n",
    "    {\n",
    "        'kernel': ['rbf', 'sigmoid'],\n",
    "        'C': [0.001, 0.01, 0.1, 1],\n",
    "        'class_weight': [\n",
    "            {0: 1, 1: 0.75},\n",
    "            {0: 1, 1: 1},\n",
    "            {0: 1, 1: 1.25},\n",
    "            {0: 1, 1: 1.5},\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "selector.plot(svc)\n",
    "svc.as_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "capqakdfmZ0u"
   },
   "source": [
    "## K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 155
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 331364,
     "status": "ok",
     "timestamp": 1539816934839,
     "user": {
      "displayName": "Kyle Hays",
      "photoUrl": "",
      "userId": "01076447387379991295"
     },
     "user_tz": 420
    },
    "id": "p44bXpytmZ0w",
    "outputId": "2b442522-2751-463a-8b10-a81c5b6fce8d"
   },
   "outputs": [],
   "source": [
    "knn = selector.search_and_test(\n",
    "    'K-Nearest Neighbors Classifier',\n",
    "    KNeighborsClassifier(),\n",
    "    {\n",
    "        'n_neighbors': range(1, 11, 2)\n",
    "    }\n",
    ")\n",
    "selector.plot(knn)\n",
    "knn.as_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jhlfiO9nmZ0-"
   },
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 20561,
     "status": "ok",
     "timestamp": 1539816956503,
     "user": {
      "displayName": "Kyle Hays",
      "photoUrl": "",
      "userId": "01076447387379991295"
     },
     "user_tz": 420
    },
    "id": "7a0EO813mZ1A",
    "outputId": "82cb2e39-c64f-483b-c879-94771cca578b"
   },
   "outputs": [],
   "source": [
    "dt = selector.search_and_test(\n",
    "    'Decision Tree Classifier',\n",
    "    DecisionTreeClassifier(),\n",
    "    {\n",
    "        'max_depth': range(1, 5),\n",
    "        'max_features': [None, 3, 6, 18],\n",
    "        'class_weight': [\n",
    "            {0: 1, 1: 0.75},\n",
    "            {0: 1, 1: 1},\n",
    "            {0: 1, 1: 1.25},\n",
    "            {0: 1, 1: 1.5},\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "selector.plot(dt)\n",
    "dt.as_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = selector.search_and_test(\n",
    "    \"Random Forest Classifier\",\n",
    "    RandomForestClassifier(),\n",
    "    {\n",
    "        'n_estimators': range(35, 46),\n",
    "        'max_depth': range(3, 13, 2),\n",
    "        'class_weight': [\n",
    "            {0: 1, 1: 0.75},\n",
    "            {0: 1, 1: 1},\n",
    "            {0: 1, 1: 1.25},\n",
    "            {0: 1, 1: 1.5},\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "selector.plot(rf)\n",
    "rf.as_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M6DXsCuimZ1e"
   },
   "source": [
    "## ADA-Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 364780,
     "status": "ok",
     "timestamp": 1539817656539,
     "user": {
      "displayName": "Kyle Hays",
      "photoUrl": "",
      "userId": "01076447387379991295"
     },
     "user_tz": 420
    },
    "id": "G5TEtQVImZ1g",
    "outputId": "fd1a76ba-e133-4405-b5cc-06489b41e123"
   },
   "outputs": [],
   "source": [
    "ada = selector.search_and_test(\n",
    "    \"ADA Boost Classifier\",\n",
    "    AdaBoostClassifier(dt.best_estimator),\n",
    "    {\n",
    "        'n_estimators': range(10, 100, 10),\n",
    "        'learning_rate': [0.001, 0.01, 1]\n",
    "    }\n",
    ")\n",
    "selector.plot(ada)\n",
    "ada.as_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selected Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector.as_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-V7SGReTmZ1-"
   },
   "source": [
    "# Conclusion\n",
    "Our best prediction accuracy was around 82-83%, our lowest measured prediction accuracy was about 80%. This is not a particularly large spread, especially considering the disparity in the time it takes for some models to train with the Grid Search to find the best hyper-parameters.\n",
    "Two things we'd like to persue in the next week that can help refine the power of our predictions would be: \n",
    "1. A comparison of the time required to train models vs. their predictive power.\n",
    "2. Possibly pursuing some solutions that increase the cost function to mitigate the high occurance of false negatives that we've seen in most of our predictions. It is in the lending body's interest to extend credit to the absolute fewest amount of people that might default on that credit. As it stands, we would be granting too much credit to people that end up not paying back their loans. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "b1aXPoNSmZxX",
    "3BuOPDwLmZzB",
    "02WV1WWbmZzP",
    "VdNaMJZdmZzY",
    "Jhls0dUSmZza",
    "38aTFc0vmZz7",
    "sXfkNDaVmZ0Y",
    "capqakdfmZ0u",
    "jhlfiO9nmZ0-",
    "M6DXsCuimZ1e"
   ],
   "name": "Project 1 (rough draft).ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
